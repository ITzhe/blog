[{"content":"拉取镜像\n1 ctr image pull docker.io/library/nginx:latest 查看容器\nctr image ls -q 创建容器\nctr c create docker.io/library/nginx:latest nginx 启动容器\nctr task start -d nginx 直接启动容器（创建容器+启动容器）\nctr run -d --net-host nginx bash 查看容器状态\nctr task ls 进入容器\nctr task exec -t --exec-id 0 nginx /bin/bash 停止容器\nctr task kill nginx 暂停容器\nctr task pause nginx ","date":"2023-02-27T16:03:31+08:00","permalink":"https://caizhe.org/p/hugo-slug/","title":"Containerd常用命令"},{"content":"最近乘着双十一有优惠，买了台香港的服务器，之前一直用公司的，打算换成自己的，写篇博客记录一下，直接开始\n系统：Ubuntu 18\n1 2 3 4 apt-get update apt-get install python-pip pip install shadowsocks apt-get install python-m2crypto 创建配置文件（默认不存在）\n1 2 3 4 5 6 7 8 9 10 11 12 cat /etc/shadowsocks.json { \u0026#34;server\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;server_port\u0026#34;: 13090, # 服务的要开放的端口 \u0026#34;local_port\u0026#34;: 1080, \u0026#34;password\u0026#34;: \u0026#34;111111\u0026#34;, # 连接的密码 \u0026#34;timeout\u0026#34;: 600, \u0026#34;method\u0026#34;: \u0026#34;aes-256-cfb\u0026#34;, # 加密算法（aes-256-gcm好像不行） \u0026#34;fast_open\u0026#34;: false, \u0026#34;workers\u0026#34;: 1, \u0026#34;prefer_ipv6\u0026#34;: false } 启动\n1 ssserver -c /etc/shadowsocks.json -d start 如果启动报错：\n1 AttributeError: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1: undefined symbol: EVP_CIPHER_CTX_cleanup 执行此命令：\n1 sed -i \u0026#34;s#EVP_CIPHER_CTX_cleanup#EVP_CIPHER_CTX_reset#g\u0026#34; /usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py 可以去GitHub上下载最新的客户端 https://github.com/shadowsocks BBR 加速\n1 2 3 4 wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh chmod +x bbr.sh ./bbr.sh lsmod | grep bbr //返回值如果有tcp_bbr模块，就说明bbr已经启动了。 连上之后可以先百度一下自己的IP，看看是不是改了。\n参考连接：https://zinyan.com/?p=6\n","date":"2023-02-27T16:02:14+08:00","permalink":"https://caizhe.org/p/hugo-slug/","title":"Shadowsocks部署"},{"content":"注意：\n两套k8s集群必须版本一致，自己试验1.13和1.15不通用。\n具体使用方法：\n1 2 3 4 5 6 7 8 9 [root@bogon ~]# kubectl get node --kubeconfig=/root/.kube/config NAME STATUS ROLES AGE VERSION bogon NotReady master 122m v1.15.1 [root@bogon ~]# kubectl get node --kubeconfig=/root/.kube/config1 NAME STATUS ROLES AGE VERSION k8s-master01 Ready master 320d v1.15.1 k8s-master02 Ready master 320d v1.15.1 k8s-master03 Ready master 320d v1.15.1 k8s-node1 Ready \u0026lt;none\u0026gt; 320d v1.15.1 ","date":"2023-02-27T15:59:25+08:00","permalink":"https://caizhe.org/p/hugo-slug/","title":"Kubectl管理多套k8s"},{"content":"关闭防火墙\nufw disable 设置主机名\n1 hostnamectl set-hostname master1.innovsharing.com 设置hosts\n1 2 172.20.55.100 api.k8s.local 172.20.55.46 master1.innovsharing.com 开启内核IPV4转发\n1 2 3 4 cat /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 bridge-nf 使得 netfilter 可以对 Linux 网桥上的 IPv4/ARP/IPv6 包过滤。比如，设置net.bridge.bridge-nf-call-iptables＝1后，二层的网桥在转发包时也会被 iptables的 FORWARD 规则所过滤。常用的选项包括：\nnet.bridge.bridge-nf-call-arptables：是否在 arptables 的 FORWARD 中过滤网桥的 ARP 包\nnet.bridge.bridge-nf-call-ip6tables：是否在 ip6tables 链中过滤 IPv6 包\nnet.bridge.bridge-nf-call-iptables：是否在 iptables 链中过滤 IPv4 包\nnet.bridge.bridge-nf-filter-vlan-tagged：是否在 iptables/arptables 中过滤打了 vlan 标签的包。\n开启IPVS支持\n1 2 3 4 5 6 7 8 9 10 11 root@master1:~# cat /etc/modules-load.d/k8s.conf br_netfilter ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh ## use nf_conntrack instead of nf_conntrack_ipv4 for Linux kernel 4.19 and later ## nf_conntrack_ipv4 nf_conntrack systemctl restart systemd-modules-load.service 重启服务器，然后执行lsmod | grep -e ip_vs -e nf_conntrack_ipv4,检查是否开启\n1 2 3 4 5 6 7 ip_vs_sh 16384 0 ip_vs_wrr 16384 0 ip_vs_rr 16384 0 ip_vs 155648 6 ip_vs_rr,ip_vs_sh,ip_vs_wrr nf_conntrack 139264 1 ip_vs nf_defrag_ipv6 24576 2 nf_conntrack,ip_vs libcrc32c 16384 2 nf_conntrack,ip_vs 安装IPVS\n1 apt-get install -y ipset ipvsadm 安装crontained\n1 2 3 4 5 6 7 8 wget https://github.com/containerd/containerd/releases/download/v1.6.8/cri-containerd-cni-1.6.8-linux-amd64.tar.gz # 或者国内下载： # wget https://download.fastgit.org/containerd/containerd/releases/download/v1.5.5/cri-containerd-cni-1.5.5-linux-amd64.tar.gz tar -C / -xzf cri-containerd-cni-1.6.8-linux-amd64.tar.gz mkdir -p /etc/containerd containerd config default \u0026gt; /etc/containerd/config.toml 配置crontained，文件位于/etc/containerd/config.toml\n1 2 3 4 5 6 7 8 9 10 11 12 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes.runc.options] SystemdCgroup = true [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;docker.io\u0026#34;] endpoint = [\u0026#34;https://bqr1dr1n.mirror.aliyuncs.com\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;k8s.gcr.io\u0026#34;] endpoint = [\u0026#34;https://registry.aliyuncs.com/google_containers\u0026#34;] sandbox_image = \u0026#34;registry.aliyuncs.com/k8sxio/pause:3.6\u0026#34; 启动crontained\n1 2 3 4 5 6 7 8 9 10 11 12 13 systemctl daemon-reload systemctl enable containerd --now root@master1:~# ctr version Client: Version: v1.6.8 Revision: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 Go version: go1.17.13 Server: Version: v1.6.8 Revision: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 UUID: 8804ad26-c5c3-4320-846a-b713c2307d5e 安装kube-VIP\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mkdir -p /etc/kubernetes/manifests/ export VIP=172.20.55.100 export INTERFACE=eth0 ctr run --rm --net-host \\ docker.io/plndr/kube-vip:v0.5.0 \\ vip /kube-vip manifest pod \\ --interface $INTERFACE \\ --vip $VIP \\ --controlplane \\ --arp \\ --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml \u0026gt; /etc/kubernetes/manifests/kube-vip.yaml kube-vip.yaml 内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 apiVersion: v1 kind: Pod metadata: creationTimestamp: null name: kube-vip namespace: kube-system spec: containers: - args: - manager env: - name: vip_arp value: \u0026#34;true\u0026#34; - name: port value: \u0026#34;6443\u0026#34; - name: vip_interface value: eth0 - name: vip_cidr value: \u0026#34;32\u0026#34; - name: cp_enable value: \u0026#34;true\u0026#34; - name: cp_namespace value: kube-system - name: vip_ddns value: \u0026#34;false\u0026#34; - name: vip_leaderelection value: \u0026#34;true\u0026#34; - name: vip_leaseduration value: \u0026#34;5\u0026#34; - name: vip_renewdeadline value: \u0026#34;3\u0026#34; - name: vip_retryperiod value: \u0026#34;1\u0026#34; - name: vip_address value: 172.20.55.100 - name: prometheus_server value: :2112 image: ghcr.io/kube-vip/kube-vip:v0.5.0 imagePullPolicy: Always name: kube-vip resources: {} securityContext: capabilities: add: - NET_ADMIN - NET_RAW volumeMounts: - mountPath: /etc/kubernetes/admin.conf name: kubeconfig hostAliases: - hostnames: - kubernetes ip: 127.0.0.1 hostNetwork: true volumes: - hostPath: path: /etc/kubernetes/admin.conf name: kubeconfig status: {} 安装kubeadm\n1 2 3 4 5 6 7 8 9 10 11 apt-get update \u0026amp;\u0026amp; apt-get install -y apt-transport-https curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF apt-get update # apt-get install -y kubelet kubeadm kubectl apt-get install kubelet=1.22.9-00 kubeadm=1.22.9-00 kubectl=1.22.9-00 systemctl enable kubelet 生成K8S 安装配置清单文件\n1 kubeadm config print init-defaults --component-configs KubeletConfiguration \u0026gt; kubeadm.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 172.20.55.46 # 本机IP地址 bindPort: 6443 nodeRegistration: criSocket: /run/containerd/containerd.sock # 使用 containerd的Unix socket 地址 imagePullPolicy: IfNotPresent name: master1 # 节点名称 taints: null --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: ipvs # kube-proxy 模式 --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像站 kind: ClusterConfiguration kubernetesVersion: 1.22.9 controlPlaneEndpoint: 172.20.55.100:6443 # 设置控制平面Endpoint地址 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} --- apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: cacheTTL: 0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.crt authorization: mode: Webhook webhook: cacheAuthorizedTTL: 0s cacheUnauthorizedTTL: 0s cgroupDriver: systemd clusterDNS: - 10.96.0.10 clusterDomain: cluster.local cpuManagerReconcilePeriod: 0s evictionPressureTransitionPeriod: 0s fileCheckFrequency: 0s healthzBindAddress: 127.0.0.1 healthzPort: 10248 httpCheckFrequency: 0s imageMinimumGCAge: 0s kind: KubeletConfiguration logging: {} memorySwap: {} nodeStatusReportFrequency: 0s nodeStatusUpdateFrequency: 0s resolvConf: /run/systemd/resolve/resolv.conf rotateCertificates: true runtimeRequestTimeout: 0s shutdownGracePeriod: 0s shutdownGracePeriodCriticalPods: 0s staticPodPath: /etc/kubernetes/manifests streamingConnectionIdleTimeout: 0s syncFrequency: 0s volumeStatsAggPeriod: 0s root@master1:~# 下载镜像\n1 2 3 4 5 6 7 kubeadm config images pull --config kubeadm.yaml # core DNS 会报错，找不到，可以打一个tag ctr -n k8s.io i pull docker.io/coredns/coredns:1.8.4 ctr -n k8s.io i tag docker.io/coredns/coredns:1.8.4 registry.aliyuncs.com/k8sxio/coredns:v1.8.4 kubeadm init --upload-certs --config kubeadm.yaml Nginx-Ingress 下载地址：https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.1/deploy/static/provider/cloud/deploy.yaml\n让控制器使用主机网络（Deployment）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ports: - containerPort: 80 name: http hostPort: 80 # 新增加 protocol: TCP - containerPort: 443 name: https hostPort: 443 # 新增加 protocol: TCP spec: hostNetwork: true # 全部使用主机网络 containers: 修改DNS策略：\n1 dnsPolicy: ClusterFirstWithHostNet 修改国内镜像：\nimage: registry.aliyuncs.com/google_containers/nginx-ingress-controller:v1.3.1 image: registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.3.1 image: registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.3.1 Tomcat测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 root@OPS:/opt# cat 02-tomcat.yaml apiVersion: v1 kind: Service metadata: name: tomcat namespace: default spec: selector: app: tomcat release: canary ports: - name: http targetPort: 8080 port: 8080 - name: ajp targetPort: 8009 port: 8009 --- apiVersion: apps/v1 kind: Deployment metadata: name: tomcat-deploy namespace: default spec: replicas: 2 selector: matchLabels: app: tomcat release: canary template: metadata: labels: app: tomcat release: canary spec: containers: - name: tomcat image: tomcat:8.5.34-jre8-alpine imagePullPolicy: IfNotPresent ports: - name: http containerPort: 8080 name: ajp containerPort: 8009 --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-myapp namespace: default annotations: kubernetes.io/ingress.class: \u0026#34;nginx\u0026#34; spec: rules: - host: www.example.com http: paths: - path: / pathType: Prefix backend: service: name: tomcat port: number: 8080 普通的 Service： 会生成servicename.namespace.svc.cluster.local的域名，会解析到 Service 对应的 ClusterIP 上，在 Pod 之间的调用可以简写成servicename.namespace， 如果处于同一个命名空间下面，甚至可以只写成 servicename 即可访问\nHeadless Service： 无头服务，就是把 clusterIP 设置为 None 的，会被解析为指定 Pod 的 IP 列表，同样还可以通过podname.servicename.namespace.svc.cluster.local访问到具体的某一个 Pod。\n","date":"2023-02-27T15:53:25+08:00","permalink":"https://caizhe.org/p/hugo-slug/","title":"Kubenertes1.22高可用安装"},{"content":" 在全民HTTPS的大趋势之下，Let\u0026rsquo;s Encrypt可是功不可没，网上文档也有很多，本身很简单的东西，网上文档比17年初已经多了很多很多，但是没想到水平参差不齐，部署到一半就不行了，简直是坑爹，就16年的老技术了，简单的几个步骤还能报错？！！！\n官方GitHub地址：https://github.com/Neilpang/acme.sh\n安装acme.sh脚本\n1 2 3 4 5 6 7 curl https://get.acme.sh | sh # 注册账户 ~/.acme.sh/acme.sh --register-account -m bob1317581669@gmail.com [Wed Feb 22 11:01:51 CST 2023] No EAB credentials found for ZeroSSL, let\u0026#39;s get one [Wed Feb 22 11:01:55 CST 2023] Registering account: https://acme.zerossl.com/v2/DV90 [Wed Feb 22 11:02:02 CST 2023] Registered [Wed Feb 22 11:02:03 CST 2023] ACCOUNT_THUMBPRINT=\u0026#39;yiMmaNSo-A27AG-jSqTkWrKKs7PgL7X9rPXApxxxxxx\u0026#39; 单域名证书 验证域名所有权\nacme.sh --issue -d cmdb.caizhe.org --nginx 安装证书\n（其实证书已经下来了，就在acme的目录下面，但是你不想放在这里话，可以执行这一步）\n1 2 3 4 [root@Bob-blog conf]# acme.sh --installcert -d cmdb.caizhe.org \\ --keypath /application/nginx/conf/cmdb_ssl/cmdb.caizhe.org.key \\ --fullchainpath /application/nginx/conf/cmdb_ssl/cmdb.caizhe.org.cer \\ --reloadcmd \u0026#34;/application/nginx/sbin/nginx -s reload\u0026#34; 查看域名情况\n1 2 3 [root@Bob-blog conf]# acme.sh --list Main_Domain KeyLength SAN_Domains Created Renew cmdb.caizhe.org \u0026#34;\u0026#34; no Wed Jun 5 09:19:13 UTC 2019 Sun Aug 4 09:19:13 UTC 2019 域名更新(之后跑个定时就行了)\nacme.sh --renew -d cmdb.caizhe.org --force 通配符证书 1 2 3 4 export Ali_Key=\u0026#34;LTAI4FyNQRVTRaxxxxxxxx\u0026#34; export Ali_Secret=\u0026#34;cE5Nhz8lRgCZ2lLxxxxxxx\u0026#34; ~/.acme.sh/acme.sh --issue --dns dns_ali -d \u0026#39;caizhe.org\u0026#39; -d \u0026#39;*.caizhe.org\u0026#39; 通配符的https必须是用DNS模式，目前支持阿里DNS和DNSpod；\n如果你是用的DNS 有支持的API接口，它会自己做验证和更新，\n关于这个Let\u0026rsquo;s Encrypt 我现在已经全站使用了近两年的时间了，没什么问题，大家可以放心使用。\ncertbot 更新通配符\ncertbot-auto --server https://acme-v02.api.letsencrypt.org/directory -d \u0026quot;*.xxx.com\u0026quot; --manual --preferred-challenges dns-01 certonly 附录Nginx配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 server { listen 80; server_name cmdb.caizhe.org; location /.well-known { alias /application/nginx/html/cmdb/.well-known; } rewrite ^(.*) https://$server_name$1 last; error_page 497 https://$server_name$request_uri; } server { listen 443 ssl; server_name cmdb.caizhe.org; ssl_certificate /root/.acme.sh/cmdb.caizhe.org/cmdb.caizhe.org.cer; ssl_certificate_key /root/.acme.sh/cmdb.caizhe.org/cmdb.caizhe.org.key; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256::!MD5; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; #ssl_session_cache builtin:1000 shared:SSL:10m; #ssl_session_timeout 1d; #ssl_session_tickets on; location / { root html/cmdb; index index.html index.htm; } } ","date":"2023-02-27T11:10:49+08:00","permalink":"https://caizhe.org/p/letsencrypt/","title":"LetsEncrypt"},{"content":"1、下载依赖安装包\n1 2 3 wget https://github.com/containerd/containerd/releases/download/v1.5.5/cri-containerd-cni-1.5.5-linux-amd64.tar.gz # 如果无法访问github可以使用下面地址 # wget https://download.fastgit.org/containerd/containerd/releases/download/v1.5.5/cri-containerd-cni-1.5.5-linux-amd64.tar.gz 2、解压\n1 tar -C / -xzf cri-containerd-cni-1.5.5-linux-amd64.tar.gz 3、配置：\n默认配置文件为 /etc/containerd/config.toml，我们可以通过如下所示的命令生成\n1 2 mkdir -p /etc/containerd containerd config default \u0026gt; /etc/containerd/config.toml 4、启动\n1 systemctl enable containerd --now 5、验证\n1 2 3 4 5 6 7 8 9 10 # ctr version Client: Version: v1.5.5 Revision: 72cec4be58a9eb6b2910f5d10f1c01ca47d231c0 Go version: go1.16.6 Server: Version: v1.5.5 Revision: 72cec4be58a9eb6b2910f5d10f1c01ca47d231c0 UUID: 38613830-5cd0-4bc4-81b4-2bcdced721d3 ","date":"2023-02-27T10:58:02+08:00","image":"https://caizhe-img.oss-cn-beijing.aliyuncs.com/blog/containerd-horizontal-color.png","permalink":"https://caizhe.org/p/containerd%E5%AE%89%E8%A3%85/","title":"Containerd安装"}]